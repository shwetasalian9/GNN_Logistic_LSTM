{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb24ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in c:\\users\\scorp\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (1.24.3)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (2.11.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (4.64.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (1.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from torch_geometric) (2.28.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from scikit-learn->torch_geometric) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\scorp\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ipype (c:\\users\\scorp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ipype (c:\\users\\scorp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ipype (c:\\users\\scorp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ipype (c:\\users\\scorp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ipype (c:\\users\\scorp\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ipype (c:\\users\\scorp\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de1e3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74dae4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_path = \"C:/Users/scorp/Downloads/train.csv\"\n",
    "test_path = \"C:/Users/scorp/Downloads/test.csv\"\n",
    "train_data = pd.read_csv(train_path).fillna(\"\")\n",
    "test_data = pd.read_csv(test_path).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976e8dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84870e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['input_text'] = train_data['title'].fillna('') + ' ' + train_data['author'].fillna('') + ' ' + train_data['text'].fillna('')\n",
    "test_data['input_text'] = test_data['title'].fillna('') + ' ' + test_data['author'].fillna('') + ' ' + test_data['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4da6e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:10000]\n",
    "Y = train_data['label'].values\n",
    "\n",
    "test_data = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a62e985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdb9f8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5200, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d6fcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   2,   4,  ..., 879, 882, 884],\n",
      "        [  1,   3,   5,  ..., 880, 883, 885]])\n",
      "tensor([[  0,   2,   4,  ..., 879, 882, 884],\n",
      "        [  1,   3,   5,  ..., 880, 883, 885]])\n",
      "printing edge nodes for test\n",
      "tensor([[   0,    0,    0,  ..., 1119, 1120, 1123],\n",
      "        [   1,    7,    8,  ..., 1121, 1121, 1124]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Load your dataset\n",
    "data = train_data\n",
    "\n",
    "\n",
    "# Create a TF-IDF vectorizer and compute TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(data['input_text'])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Threshold for cosine similarity to determine edge connections\n",
    "threshold = 0.7\n",
    "\n",
    "# Create an undirected graph based on cosine similarity\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add edges based on cosine similarity\n",
    "for i in range(len(data)):\n",
    "    for j in range(i + 1, len(data)):\n",
    "        if cosine_similarities[i, j] > threshold:\n",
    "            G.add_edge(i, j)\n",
    "\n",
    "# Renumber the nodes to be within the expected interval [0, 499]\n",
    "node_mapping = {node: i for i, node in enumerate(G.nodes())}\n",
    "G = nx.relabel_nodes(G, node_mapping)\n",
    "G_test = nx.relabel_nodes(G, node_mapping)\n",
    "\n",
    "# Convert the graph to edge_index\n",
    "edge_index_data = nx.to_edgelist(G)\n",
    "edge_index = torch.tensor([(edge[0], edge[1]) for edge in edge_index_data], dtype=torch.long).t()\n",
    "\n",
    "print(edge_index)\n",
    "\n",
    "\n",
    "# Working for test data\n",
    "\n",
    "\n",
    "# Create a TF-IDF vectorizer and compute TF-IDF matrix\n",
    "vectorizer_test = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix_test = vectorizer_test.fit_transform(test_data['input_text'])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cosine_similarities_test = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Threshold for cosine similarity to determine edge connections\n",
    "threshold = 0.7\n",
    "\n",
    "# Add edges based on cosine similarity\n",
    "for i in range(len(test_data)):\n",
    "    for j in range(i + 1, len(test_data)):\n",
    "        if cosine_similarities_test[i, j] > threshold:\n",
    "            G_test.add_edge(i, j)\n",
    "\n",
    "# Renumber the nodes to be within the expected interval [0, 499]\n",
    "node_mapping_test = {node: i for i, node in enumerate(G_test.nodes())}\n",
    "G_test = nx.relabel_nodes(G_test, node_mapping_test)\n",
    "\n",
    "# Convert the graph to edge_index\n",
    "edge_index_data_test = nx.to_edgelist(G_test)\n",
    "edge_index_test = torch.tensor([(edge[0], edge[1]) for edge in edge_index_data_test], dtype=torch.long).t()\n",
    "\n",
    "print(edge_index)\n",
    "\n",
    "print(\"printing edge nodes for test\")\n",
    "\n",
    "print(edge_index_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de14f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0503, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[0.0000, 0.0780, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0184, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load your dataset\n",
    "data = train_data\n",
    "\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "# Create a TF-IDF vectorizer for text features (e.g., title and text)\n",
    "vectorizer = TfidfVectorizer(vocabulary=vocabulary, stop_words='english')\n",
    "text_features = vectorizer.fit_transform(data['title'] + ' ' + data['text'])\n",
    "\n",
    "# Encode categorical features (e.g., author) using one-hot encoding\n",
    "categorical_features = pd.get_dummies(data['author'])\n",
    "\n",
    "# Combine text and categorical features\n",
    "node_features = pd.concat([pd.DataFrame(text_features.toarray()), categorical_features], axis=1)\n",
    "node_features_tensor = torch.tensor(node_features.values, dtype=torch.float32)\n",
    "\n",
    "print(node_features_tensor)\n",
    "\n",
    "\n",
    "# Code for test data\n",
    "# Create a TF-IDF vectorizer for text features (e.g., title and text)\n",
    "\n",
    "text_features_test = vectorizer.fit_transform(test_data['title'] + ' ' + test_data['text'])\n",
    "\n",
    "# Encode categorical features (e.g., author) using one-hot encoding\n",
    "categorical_features_test = pd.get_dummies(test_data['author'])\n",
    "\n",
    "# Combine text and categorical features\n",
    "node_features_test = pd.concat([pd.DataFrame(text_features_test.toarray()), categorical_features_test], axis=1)\n",
    "node_features_tensor_test = torch.tensor(node_features_test.values, dtype=torch.float32)\n",
    "\n",
    "print(node_features_tensor_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e65c9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124722"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = node_features_tensor.shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57f50c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123773"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features_test = node_features_tensor_test.shape[1]\n",
    "num_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2da0f630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scorp\\anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "C:\\Users\\scorp\\anaconda3\\lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "# Assuming you have node features, edge index, and labels\n",
    "node_features = node_features_tensor\n",
    "edge_index = edge_index\n",
    "labels = Y\n",
    "\n",
    "# Create a PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index, y=labels)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "loader = DataLoader([data], batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Code for test data\n",
    "\n",
    "# Load the submit data for comparison\n",
    "submit_path = \"C:/Users/scorp/Downloads/submit.csv\"\n",
    "submit_data = pd.read_csv(submit_path)\n",
    "submit_data = submit_data[:10000]\n",
    "\n",
    "y_test = submit_data['label'].values\n",
    "\n",
    "# Assuming you have node features, edge index, and labels\n",
    "node_features_test = node_features_tensor_test\n",
    "edge_index_test = edge_index_test\n",
    "\n",
    "# Create a PyTorch Geometric Data object\n",
    "data_test = Data(x=node_features_test, edge_index=edge_index_test, y=y_test)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "test_loader = DataLoader([data_test], batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "102ec876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 0\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "1\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [1/10], Loss: 0.7052026987075806\n",
      "Count 1\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "0\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [2/10], Loss: 0.701367199420929\n",
      "Count 2\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "1\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [3/10], Loss: 0.6935752034187317\n",
      "Count 3\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "1\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [4/10], Loss: 0.686258852481842\n",
      "Count 4\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "1\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [5/10], Loss: 0.6740383505821228\n",
      "Count 5\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "0\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [6/10], Loss: 0.7284423112869263\n",
      "Count 6\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "1\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [7/10], Loss: 0.6556512713432312\n",
      "Count 7\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "0\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [8/10], Loss: 0.7417843341827393\n",
      "Count 8\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "0\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [9/10], Loss: 0.7423872351646423\n",
      "Count 9\n",
      "torch.Size([1, 1])\n",
      "$$$$$\n",
      "0\n",
      "torch.Size([1, 1])\n",
      "%%%%%\n",
      "Epoch [10/10], Loss: 0.7372264862060547\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import global_max_pool as gmp\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.nn import Linear\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Graph Convolutions\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
    "\n",
    "        # Readout\n",
    "        self.lin_news = Linear(in_channels, hidden_channels)\n",
    "        self.lin0 = Linear(hidden_channels, hidden_channels)\n",
    "        self.lin1 = Linear(2*hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Graph Convolutions\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = self.conv2(h, edge_index).relu()\n",
    "        h = self.conv3(h, edge_index).relu()\n",
    "\n",
    "        # Pooling\n",
    "        h = gmp(h, batch)\n",
    "\n",
    "        # Readout\n",
    "        h = self.lin0(h).relu()\n",
    "\n",
    "        # According to UPFD paper: Include raw word2vec embeddings of news \n",
    "        # This is done per graph in the batch\n",
    "        root = (batch[1:] - batch[:-1]).nonzero(as_tuple=False).view(-1)\n",
    "        root = torch.cat([root.new_zeros(1), root + 1], dim=0)\n",
    "        # root is e.g. [   0,   14,   94,  171,  230,  302, ... ]\n",
    "        news = x[root]\n",
    "        news = self.lin_news(news).relu()\n",
    "\n",
    "        out = self.lin1(torch.cat([h, news], dim=-1))\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize the model\n",
    "model = GNN(num_features, 128, 1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "\n",
    "# Training loop\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "# Assuming you have already created the DataLoader 'loader'\n",
    "count = 0\n",
    "for epoch in range(10):    \n",
    "    model.train()  # Set the model to training mode\n",
    "    for data in loader:\n",
    "        print(\"Count \" + str(count))\n",
    "        label_num = len(data.y[0])\n",
    "        data = data.to(device)  # Move data to the device\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        output = model(data.x, data.edge_index, data.batch)  # Forward pass\n",
    "        \n",
    "        print(output.shape)\n",
    "        print(\"$$$$$\")\n",
    "        print(data.y[0][count])\n",
    "        \n",
    "        target = torch.tensor(data.y[0][count], dtype=torch.float32).view(-1, 1).to(device)\n",
    "        print(target.shape)\n",
    "        \n",
    "        loss = criterion(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        print(\"%%%%%\")\n",
    "    count = count + 1\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{10}], Loss: {loss.item()}')\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0e6848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6320\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "# model = GNN(num_features_test, 128, 1)  # num_test_features is the number of features in your test data\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "model.conv1 = GATConv(num_features_test, 128)\n",
    "model.lin_news = Linear(num_features_test, 128)\n",
    "model.eval()\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "\n",
    "\n",
    "# Iterate through the testing data\n",
    "for data in test_loader:  # Assuming you have a DataLoader for the testing data\n",
    "    \n",
    "    data = data.to(device)  # Move data to the device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index, data.batch)  # Forward pass\n",
    "        \n",
    "    # Convert the predicted probabilities to binary predictions (0 or 1)\n",
    "    predicted_labels = (output >= 0.5).int()\n",
    "    \n",
    "    predictions.append(predicted_labels.cpu().numpy())  # Convert to numpy array\n",
    "    true_labels.append(np.array(data.y))  # Convert to numpy array\n",
    "\n",
    "# Convert the lists of predictions and true labels to numpy arrays\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == true_labels).mean()\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
